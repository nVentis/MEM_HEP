{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "tfd = tfp.distributions  # pylint: disable=invalid-name\n",
    "tfb = tfp.bijectors  # pylint: disable=invalid-name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.experimental.numpy.experimental_enable_numpy_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iflow.integration import integrator\n",
    "from iflow.integration import couplings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_weighted_result(means, stddevs):\n",
    "    \"\"\" Computes weighted mean and stddev of given means and\n",
    "        stddevs arrays, using Inverse-variance weighting\n",
    "    \"\"\"\n",
    "    assert np.size(means) == np.size(stddevs)\n",
    "    assert means.shape == stddevs.shape\n",
    "    variance = 1./np.sum(1./stddevs**2, axis=-1)\n",
    "    mean = np.sum(means/(stddevs**2), axis=-1)\n",
    "    mean *= variance\n",
    "    return mean, np.sqrt(variance)\n",
    "\n",
    "def train_iflow(integrate, ptspepoch, epochs):\n",
    "    \"\"\" Run the iflow integrator\n",
    "\n",
    "    Args:\n",
    "        integrate (Integrator): iflow Integrator class object\n",
    "        ptspepoch (int): number of points per epoch in training\n",
    "        epochs (int): number of epochs for training\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray(float): value of loss (mean) and its uncertainty (standard deviation)\n",
    "\n",
    "    \"\"\"\n",
    "    means = np.zeros(epochs)\n",
    "    stddevs = np.zeros(epochs)\n",
    "    for epoch in range(epochs):\n",
    "        loss, integral, error = integrate.train_one_step(ptspepoch,\n",
    "                                                         integral=True)\n",
    "        means[epoch] = integral\n",
    "        stddevs[epoch] = error\n",
    "        _, current_precision = variance_weighted_result(means[:epoch+1], stddevs[:epoch+1])\n",
    "        if epoch % 10 == 0:\n",
    "            print('Epoch: {:3d} Loss = {:8e} Integral = '\n",
    "                  '{:8e} +/- {:8e} Total uncertainty = {:8e}'.format(epoch, loss,\n",
    "                                                                     integral, error,\n",
    "                                                                     current_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(args):\n",
    "    return tf.exp(-1*tf.sqrt(args.T[0]**2 + args.T[1]**2))\n",
    "    #return args.T[0]**3 + torch.exp(-10* args.T[1]**2)\n",
    "    \n",
    "n_dims = 2\n",
    "\n",
    "low = -2*np.ones(n_dims, dtype=np.float64)\n",
    "high = 2*np.ones(n_dims, dtype=np.float64)\n",
    "dist = tfd.Uniform(low=low, high=high)\n",
    "dist = tfd.Independent(distribution=dist,\n",
    "                        reinterpreted_batch_ndims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(3e-4, clipnorm=10.0)\n",
    "integrate = integrator.Integrator(func, dist, optimizer, loss_func='exponential')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\DevSw\\miniforge3\\envs\\normflows\\Lib\\site-packages\\iflow\\integration\\integrator.py\", line 96, in train_one_step  *\n        self.optimizer.apply_gradients(\n    File \"c:\\DevSw\\miniforge3\\envs\\normflows\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 268, in apply_gradients  **\n        grads, trainable_variables = zip(*grads_and_vars)\n\n    ValueError: not enough values to unpack (expected 2, got 0)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_iflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintegrate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[16], line 27\u001b[0m, in \u001b[0;36mtrain_iflow\u001b[1;34m(integrate, ptspepoch, epochs)\u001b[0m\n\u001b[0;32m     25\u001b[0m stddevs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(epochs)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m---> 27\u001b[0m     loss, integral, error \u001b[38;5;241m=\u001b[39m \u001b[43mintegrate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_one_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mptspepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mintegral\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m     means[epoch] \u001b[38;5;241m=\u001b[39m integral\n\u001b[0;32m     30\u001b[0m     stddevs[epoch] \u001b[38;5;241m=\u001b[39m error\n",
      "File \u001b[1;32mc:\\DevSw\\miniforge3\\envs\\normflows\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\Users\\BRYANB~1\\AppData\\Local\\Temp\\__autograph_generated_file6q0k6ovw.py:32\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_one_step\u001b[1;34m(self, nsamples, integral)\u001b[0m\n\u001b[0;32m     30\u001b[0m     loss \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mloss_func, (ag__\u001b[38;5;241m.\u001b[39mld(true), ag__\u001b[38;5;241m.\u001b[39mld(test), ag__\u001b[38;5;241m.\u001b[39mld(logp), ag__\u001b[38;5;241m.\u001b[39mld(logq)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     31\u001b[0m grads \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tape)\u001b[38;5;241m.\u001b[39mgradient, (ag__\u001b[38;5;241m.\u001b[39mld(loss), ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mdist\u001b[38;5;241m.\u001b[39mtrainable_variables), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m---> 32\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gradients\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_state\u001b[39m():\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (do_return, retval_)\n",
      "File \u001b[1;32mc:\\DevSw\\miniforge3\\envs\\normflows\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py:268\u001b[0m, in \u001b[0;36mBaseOptimizer.apply_gradients\u001b[1;34m(self, grads_and_vars)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_gradients\u001b[39m(\u001b[38;5;28mself\u001b[39m, grads_and_vars):\n\u001b[1;32m--> 268\u001b[0m     grads, trainable_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mgrads_and_vars)\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(grads, trainable_variables)\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;66;03m# Return iterations for compat with tf.keras.\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\DevSw\\miniforge3\\envs\\normflows\\Lib\\site-packages\\iflow\\integration\\integrator.py\", line 96, in train_one_step  *\n        self.optimizer.apply_gradients(\n    File \"c:\\DevSw\\miniforge3\\envs\\normflows\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 268, in apply_gradients  **\n        grads, trainable_variables = zip(*grads_and_vars)\n\n    ValueError: not enough values to unpack (expected 2, got 0)\n"
     ]
    }
   ],
   "source": [
    "train_iflow(integrate, 10000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "normflows",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

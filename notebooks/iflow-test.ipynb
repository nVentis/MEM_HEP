{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "tfd = tfp.distributions  # pylint: disable=invalid-name\n",
    "tfb = tfp.bijectors  # pylint: disable=invalid-name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.experimental.numpy.experimental_enable_numpy_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iflow.integration import integrator\n",
    "from iflow.integration import couplings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_weighted_result(means, stddevs):\n",
    "    \"\"\" Computes weighted mean and stddev of given means and\n",
    "        stddevs arrays, using Inverse-variance weighting\n",
    "    \"\"\"\n",
    "    assert np.size(means) == np.size(stddevs)\n",
    "    assert means.shape == stddevs.shape\n",
    "    variance = 1./np.sum(1./stddevs**2, axis=-1)\n",
    "    mean = np.sum(means/(stddevs**2), axis=-1)\n",
    "    mean *= variance\n",
    "    return mean, np.sqrt(variance)\n",
    "\n",
    "def train_iflow(integrate, ptspepoch, epochs):\n",
    "    \"\"\" Run the iflow integrator\n",
    "\n",
    "    Args:\n",
    "        integrate (Integrator): iflow Integrator class object\n",
    "        ptspepoch (int): number of points per epoch in training\n",
    "        epochs (int): number of epochs for training\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray(float): value of loss (mean) and its uncertainty (standard deviation)\n",
    "\n",
    "    \"\"\"\n",
    "    means = np.zeros(epochs)\n",
    "    stddevs = np.zeros(epochs)\n",
    "    for epoch in range(epochs):\n",
    "        loss, integral, error = integrate.train_one_step(ptspepoch,\n",
    "                                                         integral=True)\n",
    "        means[epoch] = integral\n",
    "        stddevs[epoch] = error\n",
    "        _, current_precision = variance_weighted_result(means[:epoch+1], stddevs[:epoch+1])\n",
    "        if epoch % 10 == 0:\n",
    "            print('Epoch: {:3d} Loss = {:8e} Integral = '\n",
    "                  '{:8e} +/- {:8e} Total uncertainty = {:8e}'.format(epoch, loss,\n",
    "                                                                     integral, error,\n",
    "                                                                     current_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-18 23:36:48.531529: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0a:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-18 23:36:48.532678: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "def func(args):\n",
    "    return tf.exp(-1*tf.sqrt(args.T[0]**2 + args.T[1]**2))\n",
    "    #return args.T[0]**3 + torch.exp(-10* args.T[1]**2)\n",
    "    \n",
    "n_dims = 2\n",
    "\n",
    "low = -2*np.ones(n_dims, dtype=np.float64)\n",
    "high = 2*np.ones(n_dims, dtype=np.float64)\n",
    "dist = tfd.Uniform(low=low, high=high)\n",
    "dist = tfd.Independent(distribution=dist,\n",
    "                        reinterpreted_batch_ndims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(3e-4, clipnorm=10.0)\n",
    "integrate = integrator.Integrator(func, dist, optimizer, loss_func='exponential')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "in user code:\n\n    File \"/root/miniforge3/envs/graphjet_pyg/lib/python3.11/site-packages/iflow/integration/integrator.py\", line 84, in train_one_step  *\n        true = tf.abs(self._func(samples))\n    File \"/tmp/ipykernel_9433/818718327.py\", line 2, in func  *\n        return tf.exp(-1*tf.sqrt(args.T[0]**2 + args.T[1]**2))\n\n    AttributeError: SymbolicTensor object has no attribute 'T'. \n            If you are looking for numpy-related methods, please run the following:\n            tf.experimental.numpy.experimental_enable_numpy_behavior()\n          \n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_iflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintegrate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 27\u001b[0m, in \u001b[0;36mtrain_iflow\u001b[0;34m(integrate, ptspepoch, epochs)\u001b[0m\n\u001b[1;32m     25\u001b[0m stddevs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(epochs)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m---> 27\u001b[0m     loss, integral, error \u001b[38;5;241m=\u001b[39m \u001b[43mintegrate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_one_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mptspepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mintegral\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     means[epoch] \u001b[38;5;241m=\u001b[39m integral\n\u001b[1;32m     30\u001b[0m     stddevs[epoch] \u001b[38;5;241m=\u001b[39m error\n",
      "File \u001b[0;32m~/miniforge3/envs/graphjet_pyg/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file685mnv1d.py:23\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_one_step\u001b[0;34m(self, nsamples, integral)\u001b[0m\n\u001b[1;32m     21\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[1;32m     22\u001b[0m samples \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mdist\u001b[38;5;241m.\u001b[39msample, (ag__\u001b[38;5;241m.\u001b[39mld(nsamples),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 23\u001b[0m true \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mabs, (\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m,), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[1;32m     25\u001b[0m     test \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mdist\u001b[38;5;241m.\u001b[39mprob, (ag__\u001b[38;5;241m.\u001b[39mld(samples),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileglfhib0o.py:12\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__func\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mexp, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m*\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39msqrt, (ag__\u001b[38;5;241m.\u001b[39mld(args)\u001b[38;5;241m.\u001b[39mT[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(args)\u001b[38;5;241m.\u001b[39mT[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m,), \u001b[38;5;28;01mNone\u001b[39;00m, fscope),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: in user code:\n\n    File \"/root/miniforge3/envs/graphjet_pyg/lib/python3.11/site-packages/iflow/integration/integrator.py\", line 84, in train_one_step  *\n        true = tf.abs(self._func(samples))\n    File \"/tmp/ipykernel_9433/818718327.py\", line 2, in func  *\n        return tf.exp(-1*tf.sqrt(args.T[0]**2 + args.T[1]**2))\n\n    AttributeError: SymbolicTensor object has no attribute 'T'. \n            If you are looking for numpy-related methods, please run the following:\n            tf.experimental.numpy.experimental_enable_numpy_behavior()\n          \n"
     ]
    }
   ],
   "source": [
    "train_iflow(integrate, 10000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "normflows",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
